{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OK2TYoWySZ-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b425ac-5c76-4db2-b0e9-edc776a62b8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t-vm2MOv4n0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f1d5f8-982b-4a68-93e9-7ecf1a6fb76c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Collecting diffusers\n",
            "  Downloading diffusers-0.29.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.23.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.7.4)\n",
            "Downloading diffusers-0.29.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers\n",
            "Successfully installed diffusers-0.29.2\n",
            "Collecting invisible_watermark\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: Pillow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from invisible_watermark) (9.4.0)\n",
            "Collecting PyWavelets>=1.1.1 (from invisible_watermark)\n",
            "  Downloading pywavelets-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from invisible_watermark) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from invisible_watermark) (4.10.0.84)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from invisible_watermark) (2.3.1+cu121)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->invisible_watermark) (12.1.105)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->invisible_watermark) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->invisible_watermark) (1.3.0)\n",
            "Downloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets, invisible_watermark\n",
            "Successfully installed PyWavelets-1.6.0 invisible_watermark-0.2.0\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.7.4)\n",
            "Downloading gTTS-2.5.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.2\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.7.4)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycryptodome\n",
            "Successfully installed pycryptodome-3.20.0\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.37.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.4.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl.metadata (37 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.37.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, tenacity, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.37.0 tenacity-8.5.0 watchdog-4.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install transformers\n",
        "!pip install diffusers\n",
        "!pip install invisible_watermark accelerate safetensors\n",
        "\n",
        "!pip install gTTS\n",
        "!pip install gtts\n",
        "!pip install pydub\n",
        "!pip install pycryptodome\n",
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "import torch\n",
        "from ipywidgets import widgets as wdg\n",
        "from ipywidgets import widgets\n",
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "from IPython.display import display, Audio, clear_output\n",
        "from gtts import gTTS\n",
        "import io\n",
        "import requests\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from base64 import b64encode\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from diffusers import DiffusionPipeline\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "import librosa\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "# Set the title of the web page\n",
        "st.title(\"Gemini Tales\")\n",
        "\n",
        "# Add a text input for the query\n",
        "query = st.text_input(\"Enter Your Query:\")\n",
        "\n",
        "\n",
        "\n",
        "# Add a button to trigger the generation\n",
        "if st.button(\"Generate\"):\n",
        "\n",
        "\n",
        "    # Load the model from the saved directory\n",
        "    directory = \"/content/drive/MyDrive/ML02/stable-diffusion-xl-base-1.0_MODEL\"\n",
        "    reloaded_pipe = DiffusionPipeline.from_pretrained(directory, torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\") # for \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "\n",
        "    # Specify the device to use for computation (e.g., \"cuda\" for GPU or \"cpu\" for CPU)\n",
        "    # Check if GPU is available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Move the diffusion pipeline to the specified device (GPU or CPU)\n",
        "    reloaded_pipe.to(device)\n",
        "\n",
        "\n",
        "    genai.configure(api_key=\"AIzaSyDdKe9SMBQEzeJACui7am3j2Q-GqMKqJPk\")\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "\n",
        "    messages = []\n",
        "\n",
        "    messages.append({\n",
        "        'role': 'user',\n",
        "        'parts': [\"Create a narrative response based on the provided query in English. The story should be within 500 words, fancy, imaginative, and include a moral or ethical lesson.\"]\n",
        "\n",
        "    })\n",
        "\n",
        "    response = model.generate_content(messages)\n",
        "    model_response_parts = response.candidates[0].content.parts  # Access the parts of the model's response\n",
        "\n",
        "    messages.append({\n",
        "        'role': 'model',\n",
        "        'parts': model_response_parts\n",
        "    })\n",
        "\n",
        "    # -------------------------------------------------------------------------------------------\n",
        "\n",
        "    ## Message Generation Function\n",
        "\n",
        "    def generate(msg):\n",
        "        messages.append({\n",
        "            'role': 'user',\n",
        "            'parts': [msg]\n",
        "        })\n",
        "\n",
        "        response = model.generate_content(messages, generation_config=genai.types.GenerationConfig(\n",
        "            candidate_count=1,  # Generate 1 different responses\n",
        "            max_output_tokens = 500000000,  # Limit output to 1000000000 tokens\n",
        "            temperature=0.7,  # Control randomness (0.7 for some variation)\n",
        "            top_k=50,  # Limit vocabulary for next word selection (balance creativity)\n",
        "        ))\n",
        "\n",
        "        model_response_parts = response.candidates[0].content.parts  # Access the parts of the model's response\n",
        "\n",
        "        words = model_response_parts[0].text.split()  # Split the text of the first part\n",
        "\n",
        "        reply = ' '.join(words[:-1])\n",
        "\n",
        "        #print(\"Model's reply:\", reply)\n",
        "        return reply\n",
        "\n",
        "    # -------------------------------------------------------------------------------------------\n",
        "\n",
        "    if query:\n",
        "        # Call your generate function here\n",
        "        output = generate(query)\n",
        "        period_index_from_end = output.rfind('.')\n",
        "\n",
        "        #print(period_index_from_end)\n",
        "\n",
        "        # Check if a period is found\n",
        "        if period_index_from_end != -1:\n",
        "            reply = output[:period_index_from_end + 1]  # Include the period\n",
        "        else:\n",
        "            # If no period is found, set the reply to the whole string\n",
        "            period_index_from_end = len(output)\n",
        "\n",
        "        print(\"Model's reply:\", reply)\n",
        "\n",
        "        def remove_special_characters(text):\n",
        "            # Remove asterisks (*) using regular expression\n",
        "            cleaned_text = re.sub(r'\\*', '', text)\n",
        "            return cleaned_text\n",
        "\n",
        "        # Remove asterisks from the model's reply\n",
        "        cleaned_reply = remove_special_characters(reply)\n",
        "\n",
        "        #------------------------\n",
        "\n",
        "        ## Text (Response) Cleaning - 1.1\n",
        "\n",
        "        def clean_response(text):\n",
        "            # Remove line breaks and extra whitespaces\n",
        "            cleaned_text = re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "            # Replace non-standard or special characters (excluding punctuation) and invalid Unicode characters with whitespace\n",
        "            cleaned_text = re.sub(r'[^\\w\\s.,!?;:()\\'\"-]', ' ', cleaned_text)\n",
        "\n",
        "            # Tokenize the text into sentences\n",
        "            sentences = nltk.sent_tokenize(cleaned_text)\n",
        "\n",
        "            # Join the sentences into a single string with proper spacing\n",
        "            cleaned_text = ' '.join(sentences)\n",
        "\n",
        "            return cleaned_text\n",
        "\n",
        "        cleaned_response = clean_response(cleaned_reply)\n",
        "        print(cleaned_response)\n",
        "\n",
        "        summary = cleaned_response\n",
        "\n",
        "        ## Function - Splitting the Summary into Chunks\n",
        "        # Function to split a summary into chunks of approximately 100 words each\n",
        "        def split_summary_into_chunks(summary):\n",
        "            # Tokenize the summary into sentences\n",
        "            sentences = nltk.tokenize.sent_tokenize(summary)\n",
        "            # Initialize an empty list to store the chunks\n",
        "            chunks = []\n",
        "            # Initialize an empty string to store the current chunk\n",
        "            current_chunk = \"\"\n",
        "            # Iterate through each sentence in the summary\n",
        "            for sentence in sentences:\n",
        "                # Check if adding the current sentence to the current chunk will keep its word count below or equal to 80\n",
        "                if len(current_chunk.split()) + len(sentence.split()) <= 60:\n",
        "                    # If yes, add the sentence to the current chunk\n",
        "                    current_chunk += \" \" + sentence\n",
        "                else:\n",
        "                    # If adding the sentence exceeds 100 words, add the current chunk to the list of chunks\n",
        "                    chunks.append(current_chunk.strip())\n",
        "                    # Start a new chunk with the current sentence\n",
        "                    current_chunk = sentence\n",
        "            # After iterating through all sentences, if there's any remaining content in the current chunk, add it to the list of chunks\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk.strip())\n",
        "            # Return the list of chunks\n",
        "            return chunks\n",
        "\n",
        "        # Usage:\n",
        "        chunks = split_summary_into_chunks(summary)\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            print(f\"Chunk {i+1}: {chunk}\\n\")\n",
        "\n",
        "        ## Splitting each Chuck into Sentences\n",
        "\n",
        "        chunks = split_summary_into_chunks(summary)\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            # Split each chunk into sentences\n",
        "            sentences = nltk.tokenize.sent_tokenize(chunk)\n",
        "            print(f\"Chunk {i+1}:\")\n",
        "            for j, sentence in enumerate(sentences):\n",
        "                print(f\"Sentence {j+1}: {sentence}\")\n",
        "            print()\n",
        "\n",
        "        ## ------------English TTS (gtts) Function (Module)----------------\n",
        "\n",
        "        def eng_gtts(text,output_path):\n",
        "          tts = gTTS(text, lang='en', slow=False)\n",
        "          tts.save(output_path)\n",
        "          print(\"Eng-Audio File Saved at : \",output_path)\n",
        "\n",
        "        # ----------Store Audio durations (Module)----------------\n",
        "\n",
        "\n",
        "        def audio_duration(file_path):\n",
        "          audio, sr = librosa.load(file_path, sr=None)\n",
        "          duration = librosa.get_duration(y=audio, sr=sr)\n",
        "          # Store the duration in the dictionary\n",
        "          audio_durations[filename] = duration\n",
        "\n",
        "        # ----------Animation Image Generation from the prompts (Module)----------------\n",
        "\n",
        "\n",
        "        def generate_image(outcome_list):\n",
        "\n",
        "          for outcome in outcome_list:\n",
        "            # Define the image prompt using the outcome\n",
        "            prompt = outcome['outcome']\n",
        "            # Generate image based on the prompt using the reloaded model\n",
        "            with torch.no_grad():\n",
        "              image = reloaded_pipe(prompt).images[0]\n",
        "            # Define the image file name based on chunk and sentence numbers\n",
        "            image_filename = f\"chunk_{outcome['chunk']}_sentence_{outcome['sentence']}.png\"\n",
        "            # Save the generated image to the output directory\n",
        "            image_path = os.path.join(output_dir_images, image_filename)\n",
        "            image.save(image_path)\n",
        "\n",
        "            print(f\"Image saved: {image_path}\")\n",
        "\n",
        "            gc.collect()  # Trigger garbage collection\n",
        "\n",
        "        # ----------Animation Video Generation from the Images (Module)----------------\n",
        "\n",
        "        # Define paths\n",
        "        chunk_images = f\"/content/sample_data/chunk_images\"\n",
        "        chunk_voices = f\"/content/sample_data/chunk_voices\"\n",
        "        chunk_video = f\"/content/sample_data/chunk_video\"\n",
        "\n",
        "        def Part_by_Part_Video():\n",
        "          # Iterate over the sorted audio durations\n",
        "          for audio_file, duration in tqdm(audio_durations.items()):\n",
        "              # Extract the filename without extension\n",
        "              filename = os.path.splitext(audio_file)[0]\n",
        "\n",
        "              # Define the input image and audio paths\n",
        "              image_path = os.path.join(chunk_images, f\"{filename}.png\")\n",
        "              audio_path = os.path.join(chunk_voices, f\"{audio_file}\")\n",
        "\n",
        "              # Define the output video path\n",
        "              output_path = os.path.join(chunk_video, f\"{filename}.mp4\")\n",
        "\n",
        "              # Create video using ffmpeg\n",
        "              os.system(f\"ffmpeg -loop 1 -i '{image_path}' -i '{audio_path}' -c:v libx264 -t {duration} -pix_fmt yuv420p '{output_path}'\")\n",
        "\n",
        "          print(\"\\nVideos created successfully!\")\n",
        "\n",
        "\n",
        "\n",
        "        ## Concatinating the Videos as per Chunks\n",
        "\n",
        "\n",
        "        # Path to the directory containing chunk videos\n",
        "        video_dir = chunk_video\n",
        "\n",
        "        # Create the output directory if it doesn't exist\n",
        "        output_dir = f\"/content/sample_data/concatenated_animation_video\"\n",
        "\n",
        "        def chunk_video_generation():\n",
        "\n",
        "          Part_by_Part_Video()\n",
        "\n",
        "          # Dictionary to store video durations for each chunk\n",
        "          chunk_video_files = {}\n",
        "\n",
        "          # Iterate through all video files in the directory\n",
        "          for filename in os.listdir(video_dir):\n",
        "              # Extract the chunk number from the video file name\n",
        "              chunk_number = filename.split(\"_\")[1]\n",
        "\n",
        "              # Add the video file to the corresponding chunk number in the dictionary\n",
        "              if chunk_number not in chunk_video_files:\n",
        "                  chunk_video_files[chunk_number] = []\n",
        "              chunk_video_files[chunk_number].append(filename)\n",
        "\n",
        "          # Concatenate video files for each chunk\n",
        "          for chunk_number, video_files in chunk_video_files.items():\n",
        "              # Sort the video files by their sentence number\n",
        "              video_files.sort(key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
        "\n",
        "              # Create a text file listing the video files\n",
        "              input_list_file = f\"{output_dir}/input_list_{chunk_number}.txt\"\n",
        "              with open(input_list_file, \"w\") as f:\n",
        "                  for video_file in video_files:\n",
        "                      f.write(f\"file '{video_dir}/{video_file}'\\n\")\n",
        "\n",
        "              # Concatenate the video files into one\n",
        "              output_video_file = f\"{output_dir}/concatenated_chunk_{chunk_number}.mp4\"\n",
        "              os.system(f\"ffmpeg -f concat -safe 0 -i {input_list_file} -c copy {output_video_file}\")\n",
        "\n",
        "              # Concatenate the video files into one using FFmpeg with GPU acceleration\n",
        "              #output_video_file = f\"{output_dir}/concatenated_chunk_{chunk_number}.mp4\"\n",
        "              #os.system(f\"ffmpeg -hwaccel cuvid -c:v h264_cuvid -f concat -safe 0 -i {input_list_file} -c:v h264_nvenc {output_video_file}\")\n",
        "\n",
        "\n",
        "          print(\"\\n --- Video Generation Complete. Check the 'concatenated_animation_video' directory. --- \\n\")\n",
        "\n",
        "        def clear_contents(directory_path):\n",
        "          if os.path.exists(directory_path):\n",
        "              # Iterate over each file in the directory\n",
        "              for filename in os.listdir(directory_path):\n",
        "                  file_path = os.path.join(directory_path, filename)\n",
        "                  # Check if the file path is a file (not a subdirectory)\n",
        "                  if os.path.isfile(file_path):\n",
        "                      # Remove the file\n",
        "                      os.remove(file_path)\n",
        "                      #print(f\"Deleted: {file_path}\")\n",
        "              print(directory_path, \" -> cleared successfully!\")\n",
        "          else:\n",
        "              print(f\"The directory {directory_path} does not exist.\")\n",
        "\n",
        "\n",
        "\n",
        "        # --------------- Create and process the output directories ----------------------------\n",
        "\n",
        "        # Chunk Audio\n",
        "        output_dir_audio = f\"/content/sample_data/chunk_voices\"\n",
        "        clear_contents(output_dir_audio)\n",
        "        os.makedirs(output_dir_audio, exist_ok=True)\n",
        "\n",
        "        # Chunk Images\n",
        "        output_dir_images = f\"/content/sample_data/chunk_images\"\n",
        "        clear_contents(output_dir_images)\n",
        "        os.makedirs(output_dir_images, exist_ok=True)\n",
        "\n",
        "        # Chunk Video (in Parts - sentence wise)\n",
        "        output_dir_video = f\"/content/sample_data/chunk_video\"\n",
        "        clear_contents(output_dir_video)\n",
        "        os.makedirs(output_dir_video, exist_ok=True)\n",
        "\n",
        "        # Chunk Video (Comple animation video for a chunk)\n",
        "        output_dir_final_video = f\"/content/sample_data/concatenated_animation_video\"\n",
        "        clear_contents(output_dir_final_video)\n",
        "        os.makedirs(output_dir_final_video, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "        # ------- Chunk_Wise Processing -------------\n",
        "\n",
        "\n",
        "\n",
        "        # ______Loop Processing START ______\n",
        "        for i, chunk in enumerate(chunks):\n",
        "\n",
        "          # Initialize an empty dictionary to store audio durations (sentences -> per chunk)\n",
        "          audio_durations = {}\n",
        "\n",
        "          # Initialize an empty list to store the outcomes (Image propmpts to generate Images)\n",
        "          outcome_list = []\n",
        "\n",
        "          # Split the chunk into sentences\n",
        "          sentences = nltk.tokenize.sent_tokenize(chunk)\n",
        "\n",
        "          # Iterate over each sentence in the chunk\n",
        "          for j, sentence in enumerate(sentences):\n",
        "\n",
        "\n",
        "          # ---- Audio Processing ----\n",
        "\n",
        "            # Generate filename for the audio file, and make the audio and store\n",
        "            filename = f\"chunk_{i+1}_sentence_{j+1}.wav\"\n",
        "            output_file_path = os.path.join(output_dir_audio, filename)\n",
        "            print(\"Language = English\")\n",
        "            eng_gtts(sentence,output_file_path)\n",
        "\n",
        "            # Store audio durations of each sentence in audio_durations (formatted after every chunk)\n",
        "            audio_duration(output_file_path)\n",
        "            time.sleep(0.5)  # Add a delay of 0.5 second after each iteration\n",
        "            #print(audio_durations)\n",
        "\n",
        "            # Pictorial Description for each sentence per chunk (stored in outcome_list)\n",
        "            outcome = (sentence)\n",
        "            outcome_dict = {\n",
        "                'chunk': i+1,\n",
        "                'sentence': j+1,\n",
        "                'outcome': outcome\n",
        "            }\n",
        "            outcome_list.append(outcome_dict) # Append the outcome dictionary to the outcome_list\n",
        "\n",
        "          audio_durations = dict(sorted(audio_durations.items())) # Sorting the audio_durations dictionary by keys\n",
        "\n",
        "          generate_image(outcome_list) # Image Generation\n",
        "          chunk_video_generation() # Animation Video Generation\n",
        "\n",
        "          # -------\n",
        "          # Clear the output after every chunk\n",
        "          clear_output(wait=True)\n",
        "\n",
        "        def concatenate_videos(input_folder, output_file):\n",
        "            # Get a list of all video files in the input folder\n",
        "            video_files = [file for file in os.listdir(input_folder) if file.endswith(\".mp4\")]\n",
        "\n",
        "            # Sort the video files based on their names\n",
        "            video_files.sort()\n",
        "\n",
        "            # Create a text file listing all video files\n",
        "            with open(\"input.txt\", \"w\") as f:\n",
        "                for file in video_files:\n",
        "                    video_path = os.path.join(input_folder, file)\n",
        "                    f.write(f\"file '{video_path}'\\n\")\n",
        "\n",
        "            # Run ffmpeg command to concatenate the videos\n",
        "            os.system(f\"ffmpeg -f concat -safe 0 -i input.txt -c copy {output_file}\")\n",
        "\n",
        "            # Remove the temporary text file\n",
        "            os.remove(\"input.txt\")\n",
        "\n",
        "            print(\"Video Created Successfully\")\n",
        "        # Display the video output (assuming it's a video file path)\n",
        "        input_folder = f\"/content/sample_data/concatenated_animation_video\"\n",
        "        # Output file path for the concatenated video\n",
        "        output_file = \"/content/sample_data/Animation_concatenated_video_ffmpeg.mp4\"\n",
        "        concatenate_videos(input_folder, output_file)\n",
        "        video_path = \"/content/sample_data/Animation_concatenated_video_ffmpeg.mp4\"  # Replace with your video file path\n",
        "        video_file = open(video_path, 'rb')\n",
        "        video_bytes = video_file.read()\n",
        "        st.video(video_bytes)\n",
        "    else:\n",
        "        st.write(\"Please enter a query to generate a response.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xylqVkAKlckV",
        "outputId": "5d3a8767-c930-4f0d-be16-70a172a589eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNIwlUWqpPIP",
        "outputId": "8e73305c-be1d-443f-9a24-0599b2b15294"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "added 22 packages, and audited 23 packages in 3s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues, run:\n",
            "  npm audit fix\n",
            "\n",
            "Run `npm audit` for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &\n"
      ],
      "metadata": {
        "id": "BIa2FidIodVt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501 & curl ipv4.icanhazip.com\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUAHN34CpSfi",
        "outputId": "b3afc78b-1a87-4aa9-f0f1-a9c317d6b709"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.124.235.51\n",
            "your url is: https://eight-boats-cry.loca.lt\n"
          ]
        }
      ]
    }
  ]
}